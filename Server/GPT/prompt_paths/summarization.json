{
    "prompt":"Provide a summary of this conversation bouth {ia_prefix} and {user_prefix} \n ### conversation: \n{messages} \n summary:",
    "model_configs":{
        "max_tokens":1024,
        "temperature":0.7,
        "top_p": 0.75,
        "top_k": 50,
        "stop":["summary"]
    }
}